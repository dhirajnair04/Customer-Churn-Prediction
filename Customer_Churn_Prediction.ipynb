{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spEEbEwUOcJC",
        "outputId": "9b587fc0-77d3-48db-dd9d-9a3789ba044b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-54fdfdbedc5d>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"TotalCharges\"].fillna(0, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
            "Model saved to churn_model2.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "# Convert TotalCharges to numeric and handle missing values\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df[\"TotalCharges\"].fillna(0, inplace=True)\n",
        "\n",
        "# Drop customerID as it's not useful for prediction\n",
        "df.drop(columns=[\"customerID\"], inplace=True)\n",
        "\n",
        "# Define selected features and target\n",
        "selected_features = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\", \"Contract\", \"InternetService\", \"PaymentMethod\", \"SeniorCitizen\", \"OnlineSecurity\", \"TechSupport\"]\n",
        "X = df[selected_features]\n",
        "y = df[\"Churn\"].map({\"No\": 0, \"Yes\": 1})  # Convert target to binary\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "\n",
        "# Create preprocessor: OneHotEncoder for categorical, StandardScaler for numerical\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numerical_features),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define base model pipeline\n",
        "base_model = RandomForestClassifier(random_state=42)\n",
        "model_pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", base_model)\n",
        "])\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    \"classifier__n_estimators\": [100, 200, 300],\n",
        "    \"classifier__max_depth\": [None, 10, 20, 30],\n",
        "    \"classifier__min_samples_split\": [2, 5, 10],\n",
        "    \"classifier__min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Save the trained model\n",
        "model_path = \"churn_model2.pkl\"\n",
        "joblib.dump(best_model, model_path)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yiWXzEatO4JG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}